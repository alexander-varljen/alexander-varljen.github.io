## Alex Varljen's ePortfolio

This is an ePortfolio that was constructed for CS 499 Computer Science Capstone, a course
at Southern New Hampshire University were Bachelor of Science in Computer Science degree
students integrate the skills we have developed over the course of our program. In this
ePortofio, you will find a professional self-assessment, a video code review of three selected
past code project artifacts, one that is software design/engineering related, one that is
algorithms and data structure related, and one that is databases related, and three artifact
enhancements with accompanying narratives. I am Alexander Varljen, a student at SNHU and the
creator of this ePortfolio and its contents. Feel free to explore the page, click any of the
links, and download any files that you wish.

You can access any of the project files mentioned on this page [here,](https://github.com/alexander-varljen/alexander-varljen.github.io)
or click the links throughout the page to see the individual files.

### Contents of This Page

   - Predictive Modeling Project
   - Data Visualizations Project
   - Database Projects
   - Feature Selection Project
   - Data Analytics Certifications


Google Drive account [here,](https://drive.google.com/file/d/10cxJDtofgnS_sbGbILLz1FpD3kXjxyGa/view?usp=sharing) 
or you can access a zipped version of the MOV video file to download for yourself [here.](https://drive.google.com/file/d/19qB4ywqz7rjAAgLcKoWCNpRRDYibPWUh/view?usp=sharing)

### Predictive Modeling Project: DAT-640 Final Project

**DAT-650 Final Project Decision Tree**

![Image](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/artifactoneimage.jpg)

**Description of the Project:**

[DAT 640 Final Project](https://docs.google.com/document/d/1MaaLNNyBRTXur2B3V0e1s8Pz4Rw5QLnk/edit?usp=sharing&ouid=105763848355793464629&rtpof=true&sd=true) is a report for a project in which I built a prediction model for a fictional insurance company "TIC". The business problem presented was to predict which customers where likely to purchase TIC's "Caravan" insurance policies. The project involved some preliminary exploratory analysis of the dataset and the construction of a pruned decision tree model, which could predict who would purchase a Caravan insurance policy with about 92% accuracy. The tools and resources used for this project included the TIC dataset, the R programming language and packages, and RStudio. Documentation of the R code used is included in the report.

[“CS 210 Project Two”](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/cs210projecttwo.zip).

### Artifact Two Enhancement: Storing and Sorting Bids Program

Link to public page with the source file (
[artifacttwo.zip](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/artifacttwo.zip) )

**Storing and Sorting Bids Program Flowchart (Original)**

![Image](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/artifacttwooriginalflowchart.png)

**Storing and Sorting Bids Program Flowchart (Enhancment)**

![Image](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/artifacttwoenhancementflowchart.png)

**Description of the Artifact:**

The original project from which this artifact enhancement was taken from was called [“CS 260 
Data Structures and Algorithms: Hash Tables and Chaining”](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/cs260hashtablesandchaining.zip), which I created for an assignment back in February of 2021. The goal of the project was to create
a program that, via four menu options, allowed the user to load bid data from a csv file into
a Hash Table data structure, display all the bids from within this data structure, find one bid
from the list stored in the Hash Table, and remove one bid from the Hash Table. My enhancement
to this artifact was adding vector sorting capacity with four new menu options, one for loading
the bids into the vector that was used for the vector sorting, one for displaying all the bids in
this vector, one for sorting the bids in that vector via selection sort, and one for sorting the
bids in that vector via quick sort. This enhancement was made in the third week of July in 2022.

**Why This Artifact was Chosen:**

I selected this artifact as my algorithms and data structures enhancement because it demonstrates
my ability to store and manipulate data using multiple forms of data structure and different
algorithms. These included an unmapped vector containing bid data and a mapped, or “hashed”,
vector, also containing the bid data from a csv file. The unmapped vector was used by the vector
sorting algorithms “quick sort” and “selection” sort, with selection sort being a simpler, but
less efficient, algorithm and selection sort being a more complex but more efficient sorting
algorithm, both of which were used to sort the bid data in ascending order. The mapped, or
“hashed”, vector is a more complex vector to construct, but provides a much faster and more
efficient way of finding an item, like a bid, than compared to using an unmapped vector. By 
including both types of vectors and their corresponding algorithms in this project, I was able
to demonstrate that I can work with multiple algorithms and data structures, which each have 
their trade-offs, but can be utilized for different problems and desired outcomes.

**Course Objectives:**

While working on this artifact enhancement, I was able to employ strategies for building
collaborative environments that enable diverse audiences to support organizational decision
making in the field of computer science. Those who want to interact with the source file,
download it for themselves, make desired changes and even, potentially, recommit changes on
an updated version of the file can easily do so via my public GitHub repository. Also, the
source code of the artifact enhancement has been made modular, which means that others change
modules, delete modules, or add their own modules with a few code changes and without much
impact on the other modules. Also, the code comments that I had written for the project make
it easier for others to add to, change, navigate, or learn from the code. For example, when
one opens the source file, they’ll notice a short description of the source code’s functionality
at the top of the file, two boxed-in code comments highlighting two main divisions in the
program, which are the modules for the hashed table data structure and those for the vector
sorting algorithms, and code comments describing each module. These help others working with
and navigating through the source code understand how everything works together so that they
can better participate. 

While working on this artifact enhancement, I was able to design, develop, and deliver
professional-quality oral, written, and visual communications that are coherent, technically
sound, and appropriately adapted to specific audiences and contexts. The second artifact covered
in the code review video is the original artifact for this enhancement, where I discussed the
original source code, module by module, and assessed my own previous work. I’ve created two
flowcharts for this artifact enhancement, one of which is a depiction of the functionality of
the artifact before the enhancements, and the other a depiction of its functionality after the
enhancements where made. I also wrote this descriptive narrative which helps explain my artifact,
its enhancements, and my intent behind the enhancements. 

While working on this artifact enhancement, I was able to design and evaluate computing
solutions that solve a given problem using algorithmic principles and computer science
practices and standards appropriate to its solution, while managing the trade-offs involved
in design choices. To solve the problem of sorting the bids, as well as show competence in
creating functional algorithms, I created two vector sorting algorithms. This, however, was
met with a trade-off in the form of having to add an extra data structure other than the hash
table, which meant that the bids needed to be loaded by the program a second time. This led
me to add two more menu options other than the two for the vector sorts, one for loading bids
to the new vector and one for displaying the bids from this new vector, along with changing
the menu labels to help the user understand the difference. This solution allowed me to manage
this trade-off and let the user decide when to load the bids a second time while also allowing
me to add two new functional sorting algorithms and meet my artifact enhancement goals.

While working on this artifact enhancement, I was able to develop a security mindset that
anticipates adversarial exploits in software architecture and designs to expose potential
vulnerabilities, mitigate design flaws, and ensure privacy and enhanced security of data and
resources. This was done by adding exception handling in the artifact enhancement’s source in
key areas, which are in the modules that contain the code used to load bid data. These let the
user know if there is an issue with the program when loading the bids. As the csv file containing
bid data could, potentially, hold thousands of “bid id’s”, “titles”, “funds”, and “amounts”,
which could be filled with the wrong type of data or come from a corrupted file, this seemed
to be the area of the most vulnerability. I also made sure that the code ran without any errors. 

**Reflection:**

As part of the process of completing my enhancements to this artifact, I had to look over the
program thoroughly to understand how it works, what enhancements where possible without changing
the whole program, and, when those enhancements were decided on, what programming decisions would
be necessary to complete those enhancements. This was made easier by my familiarity with C++,
which is the programming language that I am most familiar with. While going through this process
of reviewing the projects code, I noticed that the Hash Table data structure doesn’t easily lend 
itself to vector sorting, so I added an additional vector. This became central to many of my other
programming decisions, which includes four new menu options and an extra algorithm for loading the
new vector with the csv file data. I don’t believe that a set of menu options like this would
normally take place. However, I wanted to display multiple forms of data structures and algorithms
while using the same source of data and the same theme of the program, which was storing, adding to,
removing, and looking up bids. So, to have a coherent program with one main theme while still
demonstrating multiple data structures, I added a second set of options that were labeled differently
for the users benefit. 

### Artifact Three Enhancement: QuantigrationUpdates Database

Link to public page with the zipped file (
[artifactthree.zip](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/artifactthree.zip) )

**QuantigrationUpdates MySQL Database UML Diagram**

![Image](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/artifactthreemysqldiagram.png)

**QuantigrationUpdates MongoDB Database UML Diagram**

![Image](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/artifactthreemongodbdiagram.png)

**Description of Artifact**

The original project from which the artifact enhancement was taken was called [“DAD 220 Project One”](https://github.com/alexander-varljen/alexander-varljen.github.io/blob/main/dad220projectone.docx),
which I created for an assignment back in August of 2020. The goal of this project was to create a
database called “QuantigrationUpdates” with three tables called “Customers”, “Orders”, and “RMA”,
query their records, update their records, delete their records, and download the records from the
“Orders” table onto a csv file using MySQL. My enhancement to this artifact was creating a similar 
database, also called “QuantigrationUpdates”, with three collections that contain the same fields,
use similar queries, updates, deletions, and a download while using MongoDB commands on a MongoDB
shell. My enhancement also included adding two levels of user accounts to provide extra security to
the database. This enhancement was completed in the last week of July 2022.

**Why This Artifact Was Chosen**

I chose this artifact because it allowed me to show a range of CRUD skills with Databases using
MongoDB, a popular database tool. By using MongoDB commands, I was able to create a database for a
fictional business with three collections, each containing multiple fields of data, as well as create
a view of one of the collections. I was also able to add records to each database using correct
commands, display records with queries, update specific records using query and update commands, and
delete records using query and delete commands. I was also able to export a collection to a csv file
with a MongoDB command. I was also able to go beyond the functionality of the original project by
adding password secured user accounts.

**Course Objectives**

While working on this artifact enhancement, I was able to employ strategies for building
collaborative environments that enable diverse audiences to support organizational decision
making in the field of computer science. My enhanced artifact zipped file is open for anyone to
download and view for themselves from my public GitHub page. This file contains the three csv files
used in the artifact’s enhancement, as well as a txt file containing all the MongoDB commands used,
so that anyone who wishes to reconstruct the database themselves and conduct the same or different
queries can do so. Also, if someone wishing to work with these MongoDB commands needs more
information about what the commands are meant to accomplish, there is a word document with screenshots
of the commands being used with written explanations for them located in the same zipped file. Also,
the public GitHub page that this artifact enhancement can be found on grants others the opportunities
to ask questions and propose suggestions pertaining to this and all the other projects and files
located on the page. 

While working on this artifact enhancement, I was able to design, develop, and deliver
professional-quality oral, written, and visual communications that are coherent, technically sound,
and appropriately adapted to specific audiences and contexts. In terms of oral communication for
this artifact, this was the last artifact covered in the code review video, where I went over
screenshots of each of the MySQL commands used and discussed their purpose and potential areas
of change. In terms of written communication, the zipped file for this artifact contains a short
readme describing the other five files that are contained in the zipped file, one of which is a
word document, which contains screenshots of the MongoDB commands used and their output, along
with explanations for the commands. I’ve also written this accompanying narrative to describe
the original artifact, explain my enhancements, and justify why the enhancements where made.
In terms of visual communication, I constructed two UML diagrams, on for the original MySQL
QunatigrationUpdates database, and the other for the enhanced MongoDB database so that others
can visualize the structure of these databases. 

While working on this artifact enhancement, I was able to demonstrate an ability to use well-founded
and innovative techniques, skills, and tools in computing practices for the purpose of implementing
computer solutions that deliver value and accomplish industry-specific goals. Some of the well-founded
techniques and skills that were used during this enhancement was a full display of CRUD operations,
as I created a database using MongoDB commands, queried the collections of that database to find specific
information, updated and added several fields in that database, and deleted some fields. The tools that
I used during this artifact enhancement include a MongoDB Enterprise Server 6.0 and a MongoDB Shell,
which I downloaded to my local device, and a Microsoft command prompt that was used to access the
MongoDB Shell and perform MongoDB commands. 

While working on this artifact enhancement, I was able to develop a security mindset that anticipates
adversarial exploits in software architecture and designs to expose potential vulnerabilities,
mitigate design flaws, and ensure privacy and enhanced security of data and resources. I demonstrated
this by creating two password secured user accounts, one of which was an administrative account
that was granted read/write access to all databases in the server, and the other was a user account
that was granted read/write access to the QuantigrationUpdates database. I would also note that,
after running each MongoDB command, a message displaying either a warning for errors or the task
that was completed by the command is displayed. You can see these message outputs after the commands
I used in the word document containing screenshots marked “CS 499 Artifact Three”, which is located
in this artifact enhancement’s zipped file.

**Reflection**

Since I’d already learned how to use MongoDB commands previously, much of the new knowledge I gained
from working on this enhancement has been while adding a local Mongo shell, Mongo Server, and other
necessary tools to my computer. This was also the main source of the challenges that I had in completing
this project, as I have never downloaded and used MongoDB tools on my local device before. However,
after seeking help from tech support, the internet, and some trial and error, I was able to use my 
own working MongoDB shell and server to complete this artifact enhancement. 

### References:

Grupman, C. (2022). 8 Data Analyst Skills Employers Need to See in 2022. _Dataquest._ [https://www.dataquest.io/blog/data-analyst-skills/](https://www.dataquest.io/blog/data-analyst-skills/)

Berkely Extension. (2022). 11 Data Scientist Skills Employers Want to See in 2022. _Berkely Extension._ [https://bootcamp.berkeley.edu/blog/data-scientist-skills/](https://bootcamp.berkeley.edu/blog/data-scientist-skills/) 
